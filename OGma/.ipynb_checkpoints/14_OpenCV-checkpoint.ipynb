{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[[239 240 238]\n",
      "  [240 241 239]\n",
      "  [240 241 239]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[242 243 241]\n",
      "  [242 243 241]\n",
      "  [242 243 241]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[244 245 243]\n",
      "  [244 245 243]\n",
      "  [244 245 243]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n",
      "(2040, 1360, 3)\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "# Read BGR\n",
    "img = cv2.imread(\"14_OpenCV_1.jpg\", 1)\n",
    "print(type(img))\n",
    "print(img)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[239 240 240 ... 255 255 255]\n",
      " [242 242 242 ... 255 255 255]\n",
      " [244 244 244 ... 255 255 255]\n",
      " ...\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]]\n",
      "(2040, 1360)\n"
     ]
    }
   ],
   "source": [
    "# Read Grayscale\n",
    "img = cv2.imread(\"14_OpenCV_1.jpg\", 0)\n",
    "print(type(img))\n",
    "print(img)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"14_OpenCV_1.jpg\", 1)\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"14_OpenCV_1.jpg\", 1)\n",
    "res_img = cv2.resize(img, (100, 50))\n",
    "cv2.imshow(\"Res_Image\", res_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_img = cv2.resize(img, (img.shape[1] // 4, img.shape[0] // 4))\n",
    "cv2.imshow(\"Res_Image\", res_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[ 424  261  529  529]\n",
      " [ 232 1424  501  501]]\n"
     ]
    }
   ],
   "source": [
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "img = cv2.imread(\"14_OpenCV_1.jpg\")\n",
    "# Grayscaling a BGR colored image\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray_img, scaleFactor=1.05, minNeighbors=5)\n",
    "\n",
    "print(type(faces))\n",
    "print(faces)\n",
    "\n",
    "for x, y, w, h in faces:\n",
    "    img = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 3)\n",
    "\n",
    "resized = cv2.resize(img, (img.shape[1] // 4, img.shape[0] // 4))\n",
    "\n",
    "cv2.imshow(\"Gray\", resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video 1st Frame Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[[[250 167 168]\n",
      "  [255 180 181]\n",
      "  [254 199 192]\n",
      "  ...\n",
      "  [ 28   5  16]\n",
      "  [ 23   8  16]\n",
      "  [ 23   8  16]]\n",
      "\n",
      " [[242 200 202]\n",
      "  [239 198 200]\n",
      "  [244 202 197]\n",
      "  ...\n",
      "  [ 26   5  16]\n",
      "  [ 24   6  16]\n",
      "  [ 25   7  18]]\n",
      "\n",
      " [[236 182 180]\n",
      "  [237 183 181]\n",
      "  [235 190 180]\n",
      "  ...\n",
      "  [ 28   5  18]\n",
      "  [ 24   6  16]\n",
      "  [ 24   6  16]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 86  78  90]\n",
      "  [ 86  78  90]\n",
      "  [ 93  75  95]\n",
      "  ...\n",
      "  [ 26  30   9]\n",
      "  [ 23  32  11]\n",
      "  [ 23  32  11]]\n",
      "\n",
      " [[ 89  79  93]\n",
      "  [ 87  76  91]\n",
      "  [ 95  73 100]\n",
      "  ...\n",
      "  [ 27  29   8]\n",
      "  [ 23  31   9]\n",
      "  [ 22  29   8]]\n",
      "\n",
      " [[ 87  78  87]\n",
      "  [ 87  78  87]\n",
      "  [ 93  73 100]\n",
      "  ...\n",
      "  [ 30  26  13]\n",
      "  [ 27  29   8]\n",
      "  [ 27  29   8]]]\n"
     ]
    }
   ],
   "source": [
    "video = cv2.VideoCapture(0)\n",
    "check, frame = video.read()\n",
    "print(check)\n",
    "print(frame)\n",
    "# time.sleep(3)\n",
    "cv2.imshow(\"Capturing\", frame)\n",
    "cv2.waitKey(0)\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Capture in Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "video = cv2.VideoCapture(0)\n",
    "a = 1\n",
    "while True:\n",
    "    a += 1\n",
    "    check, frame = video.read()\n",
    "    # print(\"#\" * 20)\n",
    "    # print(check)\n",
    "    # print(frame)\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow(\"Capturing\", gray)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "print(a)\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Detection from Video in Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "video = cv2.VideoCapture(0)\n",
    "a = 1\n",
    "while True:\n",
    "    a += 1\n",
    "    check, frame = video.read()\n",
    "    # print(\"#\" * 20)\n",
    "    # print(\"Check : \", check)\n",
    "    # print(\"FRAME : \")\n",
    "    # print(frame)\n",
    "    faces = face_cascade.detectMultiScale(frame, scaleFactor=1.05, minNeighbors=5)\n",
    "    # print(\"FACE : \")\n",
    "    # print(faces)\n",
    "\n",
    "    for x, y, w, h in faces:\n",
    "        frame = cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "\n",
    "    resized = cv2.resize(frame, (frame.shape[1], frame.shape[0]))\n",
    "    cv2.imshow(\"Capturing\", resized)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "print(a)\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from datetime import datetime\n",
    "\n",
    "first_frame = None\n",
    "\n",
    "# status_list = [None, None]\n",
    "# times = []\n",
    "# df = pd.DataFrame(columns=[\"Start\", \"End\"])\n",
    "\n",
    "video = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    check, frame = video.read()\n",
    "\n",
    "    # status = 0\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "    if first_frame is None:\n",
    "        first_frame = gray\n",
    "        continue\n",
    "    delta_frame = cv2.absdiff(first_frame, gray)\n",
    "    thresh_delta = cv2.threshold(delta_frame, 30, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh_delta = cv2.dilate(thresh_delta, None, iterations=0)\n",
    "    major = cv2.__version__.split('.')[0]\n",
    "    if major == '3':\n",
    "        ret, contours, hierarchy = cv2.findContours(thresh_delta.copy(),\n",
    "                                                    cv2.RETR_EXTERNAL,\n",
    "                                                    cv2.CHAIN_APPROX_SIMPLE)\n",
    "    else:\n",
    "        contours, hierarchy = cv2.findContours(thresh_delta.copy(),\n",
    "                                                   cv2.RETR_EXTERNAL,\n",
    "                                                   cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) < 1000:\n",
    "            continue\n",
    "\n",
    "        # status = 1\n",
    "        \n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
    "\n",
    "    # status_list.append(status)\n",
    "    # status_list = status_list[-2:]\n",
    "    # if status_list[-1] == 1 and status_list[-2] == 0:\n",
    "        # times.append(datetime.now().time())\n",
    "    # if status_list[-1] == 0 and status_list[-2] == 1:\n",
    "        # times.append(datetime.now().time())\n",
    "    \n",
    "    frame = cv2.resize(frame, (frame.shape[1] // 2, frame.shape[0] // 2))\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    gray = cv2.resize(gray, (gray.shape[1] // 2, gray.shape[0] // 2))\n",
    "    cv2.imshow(\"Capturing\", gray)\n",
    "    delta_frame = cv2.resize(delta_frame, (delta_frame.shape[1] // 2, delta_frame.shape[0] // 2))\n",
    "    cv2.imshow(\"Delta\", delta_frame)\n",
    "    thresh_delta = cv2.resize(thresh_delta, (thresh_delta.shape[1] // 2, thresh_delta.shape[0] // 2))\n",
    "    cv2.imshow(\"Thresh\", thresh_delta)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# print(status_list)\n",
    "# print(times)\n",
    "# for i in range(0, len(times), 2):\n",
    "    # df = df.append({\"Start\": times[i], \"End\": times[i+1]}, ignore_index=True)\n",
    "# df.to_csv(\"14_OpenCV.csv\")\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
